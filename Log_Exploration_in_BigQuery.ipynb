{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup\n",
        "* The following steps are used for setup only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update below\n",
        "bq_dataset = \"DATASET_NAME\"\n",
        "bq_project = \"PROJECT_NAME\"\n",
        "bq_location = \"US\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade firebase-admin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "# Use a service account.\n",
        "# cred = credentials.Certificate('path/to/serviceAccount.json')\n",
        "try:\n",
        "  app = firebase_admin.initialize_app()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "db = firestore.client(database_id=\"o11ydemo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Looking for the logs that we generated and logged to stdout.  They are in JSON format that we can natively use with BigQuery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "# Look for logs with LLM called, using the JSON format\n",
        "sql = f\"\"\"\n",
        "select TIMESTAMP(jsonPayload.timestamp) AS parsed_timestamp,*\n",
        "from `{bq_project}.observability_demo.run_googleapis_com_stdout`\n",
        "where jsonPayload.message = 'scoring question'\n",
        "\"\"\"\n",
        "log_df = bpd.read_gbq_query(sql)\n",
        "log_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pulling the scoring information, which answers were answered correctly. We did not log the full question on purpose because we can show that we can now join it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "select jsonPayload.timestamp,jsonPayload.qid, jsonPayload.correct\n",
        "from `{bq_project}.observability_demo.run_googleapis_com_stdout`\n",
        "where jsonPayload.message = 'scoring question'\n",
        "\"\"\"\n",
        "print(sql)\n",
        "log_df = bpd.read_gbq_query(sql)\n",
        "log_df.head(50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We connect to Firestore and and pull down all the questions into a dataframe to be used by our notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_dict = log_df.to_dict()\n",
        "\n",
        "questions_array = []\n",
        "for collection in [\"FLASH\",\"FLASHLITE\",\"GEMMA3\"]:\n",
        "  doc_ref = db.collection(collection)\n",
        "  docs = doc_ref.stream()\n",
        "  for doc in docs:\n",
        "      # print(f\"{doc.id} => {doc.to_dict()}\")\n",
        "      questions_dict = doc.to_dict()\n",
        "      questions_dict['qid'] = doc.id\n",
        "      questions_array.append(questions_dict)\n",
        "\n",
        "questions_df = bpd.DataFrame(questions_array)\n",
        "second_questions_df = questions_df.copy()\n",
        "questions_df.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge the two together - essentially a join, you've now joined Firestore data with your logs, enriching them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lookup_df = log_df.merge(questions_df,left_on='qid',right_on='qid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We can do some preliminary counts to show how many, split by model, were correctly answered and plot it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count_df = lookup_df.groupby([\"code\",\"correct\"]).count()\n",
        "count_df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot value counts\n",
        "count_df.plot(kind='bar', color='skyblue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finally, we pull your prompt to see the responses from the various models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latest_sql = \"\"\"\n",
        "with filter_table as (\n",
        "    select jsonPayload.session_id as session_id, RANK() OVER (PARTITION BY jsonPayload.message ORDER BY TIMESTAMP(jsonPayload.timestamp) DESC) AS rnk\n",
        "    from `observability_demo.run_googleapis_com_stdout`\n",
        "    where jsonPayload.message = 'scoring question' and jsonPayload.session_id is not null and jsonPayload.answer is not null\n",
        "    qualify rnk < 10\n",
        ")\n",
        "select jsonPayload.session_id, jsonPayload.timestamp, jsonPayload.qid, jsonPayload.correct, jsonPayload.model, jsonPayload.answer\n",
        "from `observability_demo.run_googleapis_com_stdout`\n",
        "where jsonPayload.message = 'scoring question'\n",
        "and jsonPayload.session_id in (\n",
        "  select session_id\n",
        "  from filter_table\n",
        ")\n",
        "\"\"\"\n",
        "latest_df = bpd.read_gbq_query(latest_sql)\n",
        "\n",
        "latest_lookup_df = latest_df.merge(questions_df,left_on='qid',right_on='qid')\n",
        "latest_lookup_df.head(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts_sql = \"\"\"\n",
        "with inner_query as (\n",
        "select session_id\n",
        "from (\n",
        "  select JSON_QUERY(cast(data as string),'$.session_id') as session_id, JSON_QUERY(cast(data as string),'$.model'), JSON_QUERY(cast(data as string),'$.prompt') , JSON_QUERY(cast(data as string),'$.formatted_response') , cast(REPLACE(JSON_QUERY(cast(data as string),'$.session_id'),'\"','') as int),\n",
        "  rank() over (ORDER BY cast(REPLACE(JSON_QUERY(cast(data as string),'$.session_id'),'\"','') as int) desc) as rnk\n",
        "  from observability_demo.logPromptsAndResponses\n",
        "  qualify rnk < 10)\n",
        ")\n",
        "select JSON_QUERY(cast(data as string),'$.session_id'), JSON_QUERY(cast(data as string),'$.model'), JSON_QUERY(cast(data as string),'$.prompt') , JSON_QUERY(cast(data as string),'$.formatted_response') , cast(REPLACE(JSON_QUERY(cast(data as string),'$.session_id'),'\"','') as int)\n",
        "from observability_demo.logPromptsAndResponses\n",
        "where JSON_QUERY(cast(data as string),'$.session_id') in (\n",
        "  select *\n",
        "  from inner_query\n",
        ")\n",
        "\"\"\"\n",
        "prompts_df = bpd.read_gbq_query(prompts_sql)\n",
        "\n",
        "prompts_df.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "IAwed0oTAdt9"
      ],
      "name": "Log Exploration in BigQuery",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
